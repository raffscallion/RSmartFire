{
    "contents" : "###  DevelopPrimaryPolygons.R\n# \n# First attempt at creating primary polygons from Tranche 1 data sets\n#\n#   1. Load preprocessed data from shapefile (or directly from R potentially)\n#   2. Look for intersecting polygons\n#   3. Create a crosswalk list for later use\n#   4. Create a best-guess polygon (based on hierarchy?)\n#   5. Write out to a constant format for later processing\n#\n\n### Parameters to change\n# The working directory\nsetwd(\"C:/Users/Sean/Google Drive/Work/R Code/SF3/SF_Algorithms\")\n# The list of reprocessed Tranche1 datasets (in same path)\n# The earliest listed dataset takes precedence over subsequent data sets\ninputs <- list('MN_WF', 'MN_RX', 'GeoMacProcessed')\n# The location of the input Tranche1 datasets\ninpath <- \"./InputData/Tranche1\"\noutpath <- \"./FinalData/Tranche1\"\noutname <- 'Tranche1Polygons'\n\n# Required packages\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(dplyr)\n\n# Load shapefiles to a list\ndatasets <- lapply(inputs, function(x) {readOGR(dsn=inpath, layer=x, stringsAsFactors=FALSE)})\n\n# Look for intersecting polygons across all layers two at a time (Magic!)\ncombos <- combn(datasets, 2, function(x) gIntersects(x[[1]],x[[2]], byid=TRUE), simplify=FALSE)\nints <- lapply(combos, which, arr.ind=TRUE)\n\n# Now we have the full list of intersections, what do we do?\n# Throw out any polys that intersect with the first listed dataset,\n# then throw out remaining polys that intersect with the next listed dataset.\n# This method ignores time.  \n\n# Here are the different combinations of i and j\nn.combos <- length(ints)\nn.datasets <- length(datasets)\nx <- 1\ni <- 1\nj <- 2\npairs <- matrix(ncol=2, nrow=n.combos)\nwhile (x <= n.combos) {\n  pairs[x,1] <- i\n  pairs[x,2] <- j\n  j <- j+1\n  if (j > n.datasets) {\n    i <- i+1\n    j <- i+1\n  }\n  x <- x+1\n}\n\n# Now walk through the list of intersections and build the list to discard\nn.intersects <- length(unlist(ints))/2\n# make a structure to store the list (dataset, dup.id)\ntoss <- setNames(data.frame(matrix(ncol = 2, nrow = n.intersects)),c(\"dataset\", \"dup.id\"))\n\ni <- 1\nfor (x in 1:n.combos) {\n  dups <- ints[[x]][,1] \n  dup.polys <- length(dups)\n  for (y in 1:dup.polys) {\n    toss$dataset[i] <- pairs[x,2]\n    toss$dup.id[i] <- dups[[y]]\n    i <- i+1\n  }\n}\n\n# the distinct list of conflicting polygons to toss\ntoss.distinct <- distinct(toss)\n\n# This method does not associate or count data sets that conflicted, which should be improved.\n# For now, we save out the variable 'ints,' which contains all of the intersections \n# and can later be used to reconstruct associations.\nsave(ints, file = \"tranche1intersections.RData\")\n\n# Remove conflicting polygons from each dataset\nds.index <- seq(1:n.datasets)\nremoveConflicts <- function(x, y) {\n  toss.1 <- filter(toss.distinct, dataset == y) %>%\n    mutate(sf_id = dup.id)\n  to.keep <- anti_join(x@data, toss.1, by='sf_id') %>%\n    arrange(sf_id)\n  to.keep.v <- unlist(to.keep$sf_id)\n  no.dup <- x[x$sf_id %in% to.keep.v,]\n}\n\ndatasets.no.dups <- mapply(removeConflicts, datasets, ds.index)\n\n\n# Delete all non-sf fieldnames\ncleanFields <- function(x) {\n  x@data <- (select(x@data, starts_with('sf_')))\n  return(x)\n}\n  \ndatasets.no.dups <- mapply(cleanFields, datasets.no.dups)\n\n\n# Merge together and write to shapefile\n#To make them uniform we can write a function using the spChFIDs function from sp:\nmakeUniform<-function(SPDF, ds){\n  pref<-as.character(ds)  #just putting a number in front.\n  newSPDF<-spChFIDs(SPDF,as.character(paste(pref,rownames(as(SPDF,\"data.frame\")),sep=\"_\")))\n  return(newSPDF)\n}\nnewIDs<-mapply(makeUniform, datasets.no.dups, ds.index)\nmerged <- do.call(rbind, newIDs)\n\nwriteOGR(merged, outpath, outname, 'ESRI Shapefile')\n\n",
    "created" : 1430781000592.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2224949050",
    "id" : "990AEB1",
    "lastKnownWriteTime" : 1428364407,
    "path" : "C:/Users/Sean/Google Drive/Work/R Code/SF3/SF_Algorithms/Code/DevelopPrimaryPolygons.R",
    "project_path" : "Code/DevelopPrimaryPolygons.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}