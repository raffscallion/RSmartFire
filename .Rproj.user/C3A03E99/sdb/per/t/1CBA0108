{
    "contents" : "###  DevelopTranche2Polygons.R\n# \n# First attempt at creating final combined polygons from Tranche 2 data sets\n#\n#   1. Load preprocessed data from shapefile (or directly from R potentially)\n#   2. Look for intersecting polygons\n#   3. Create a crosswalk list for later use\n#   4. For each intersection, determine if they are within date range\n#   5. Append all information from lower rank data to a blob in high rank data\n#   6. Write out to a constant format for later processing\n#\n\n### Parameters to change\n# The working directory\nsetwd(\"C:/Users/Sean/Google Drive/Work/R Code/SF3/SF_Algorithms\")\n# The list of reprocessed Tranche1 datasets (in same path)\n# The earliest listed dataset takes precedence over subsequent data sets\ninputs <- list('MN_DNR_WF_Tranche2', 'NASF_Tranche2', 'FACTS_Tranche2')\n# The location of the input Tranche1 datasets\ninpath <- \"./FinalData/Tranche2/\"\noutpath <- \"./FinalData/Tranche2\"\noutname <- 'Tranche2Polygons'\n\n# Required packages\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(dplyr)\n\n# Load shapefiles to a list (previously saved as RDS files)\ndatasets <- lapply(inputs, function(x) {readRDS(paste0(inpath, x, '.RDS'))})\n\n# Look for intersecting polygons across all layers two at a time (Magic!)\ncombos <- combn(datasets, 2, function(x) gIntersects(x[[1]],x[[2]], byid=TRUE), simplify=FALSE)\nints <- lapply(combos, which, arr.ind=TRUE)\n\n# the ints variable contains the pairs that intersect, but need to parse it to get\n# the specific data sets and ids for each intersect. That is all the mess below\n\n# Here are the different combinations of i and j\nn.combos <- length(ints)\nn.datasets <- length(datasets)\nx <- 1\ni <- 1\nj <- 2\npairs <- matrix(ncol=2, nrow=n.combos)\nwhile (x <= n.combos) {\n  pairs[x,1] <- i\n  pairs[x,2] <- j\n  j <- j+1\n  if (j > n.datasets) {\n    i <- i+1\n    j <- i+1\n  }\n  x <- x+1\n}\n\n# Now walk through the list of intersections and build the list to discard\nn.intersects <- length(unlist(ints))/2\n# make a structure to store the list (ds1, dup.id1 ,ds2, dup.id2)\ncandidates <- setNames(data.frame(matrix(ncol = 4, nrow = n.intersects)),c(\"ds1\", \"dup.id1\", \"ds2\", \"dup.id2\"))\n\ni <- 1\n\nfor (x in 1:n.combos) {\n  dups.ds1 <- ints[[x]][,2] \n  dups.ds2 <- ints[[x]][,1]\n  dup.polys <- length(dups.ds1)\n  if (dup.polys==0) next\n  for (y in 1:dup.polys) {\n    candidates$ds1[i] <- pairs[x,1]\n    candidates$dup.id1[i] <- dups.ds1[[y]]\n    candidates$ds2[i] <- pairs[x,2]\n    candidates$dup.id2[i] <- dups.ds2[[y]]\n    \n    i <- i+1\n  }\n}\n\n\n# Now for each candidate intersection, check to see if they intersect in time (or are close?)\ncheckDates <- function(ds1, id1, ds2, id2) {\n  start1 <- datasets[[ds1]][id1,]$sf_start\n  end1 <- datasets[[ds1]][id1,]$sf_end \n  start2 <- datasets[[ds2]][id2,]$sf_start\n  end2 <- datasets[[ds2]][id2,]$sf_end\n  if ((abs(start1 - start2) < 3) | (abs(end1 - end2) < 3)) {\n    return(TRUE)\n  } else return(FALSE)\n}\ncandidates$overlap <- mapply(checkDates, candidates$ds1, candidates$dup.id1, candidates$ds2, candidates$dup.id2)\n\n# Now, for all candidates where overlap is true, remove the secondary data set\ntoss <- filter(candidates, overlap==TRUE)\n\n# Remove conflicting polygons from each dataset\nds.index <- seq(1:n.datasets)\nremoveConflicts <- function(x, y) {\n  toss.1 <- filter(toss, ds2 == y) %>%\n    mutate(sf_id = as.character(dup.id2))\n  to.keep <- anti_join(x@data, toss.1, by='sf_id') %>%\n    arrange(sf_id)\n  to.keep.v <- unlist(to.keep$sf_id)\n  no.dup <- x[x$sf_id %in% to.keep.v,]\n}\n\ndatasets.no.dups <- mapply(removeConflicts, datasets, ds.index)\n\n# Delete all non-sf fieldnames\ncleanFields <- function(x) {\n  x@data <- (select(x@data, starts_with('sf_')))\n  return(x)\n}\n\ndatasets.no.dups <- mapply(cleanFields, datasets.no.dups)\n\n\n# Merge together and write to shapefile\n#To make them uniform we can write a function using the spChFIDs function from sp:\nmakeUniform<-function(SPDF, ds){\n  pref<-as.character(ds)  #just putting a number in front.\n  newSPDF<-spChFIDs(SPDF,as.character(paste(pref,rownames(as(SPDF,\"data.frame\")),sep=\"_\")))\n  return(newSPDF)\n}\nnewIDs<-mapply(makeUniform, datasets.no.dups, ds.index)\nmerged <- do.call(rbind, newIDs)\n\nwriteOGR(merged, outpath, outname, 'ESRI Shapefile')\n",
    "created" : 1430778506755.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3070464953",
    "id" : "1CBA0108",
    "lastKnownWriteTime" : 1431112301,
    "path" : "C:/Users/Sean/Google Drive/Work/R Code/SF3/SF_Algorithms/Code/DevelopTranche2Polygons.R",
    "project_path" : "Code/DevelopTranche2Polygons.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}